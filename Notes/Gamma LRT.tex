\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm} 
\usepackage{xcolor}     % For the \textcolor{}{} command
\usepackage{mathrsfs}   % For the \mathscr{} font

\usepackage{natbib} % For citation functions like \citet and \citep


\newcommand{\bG}{\mathbb{G}}
\newcommand{\bF}{\mathbb{F}}
\newcommand{\bP}{\mathbb{P}}

\newcommand{\sW}{\mathscr{W}}
\newcommand{\swe}{\mathscr{W}(\eta)}

\newcommand{\dfdg}{d \bF / d \bG}
\newcommand{\dfdgfrac}{\frac{d \bF}{d \bG}}


\title{Gamma LRT}
\date{}


\begin{document}

\maketitle

This document describes the steps to obtain the tail function for the importance sampling weights in Gamma distribution example. 
We use an Exponential distribution as the proposal dist with pdf $g(x)$, and our target distribution is Gamma with pdf $f(x)$.

Steps are as follows (I think!)
\textcolor{blue}{This looks really good Payman. I just added a couple notes in blue.}

Step 1. Set the target distribution, $f(x)$ as a Gamma distribution with $\alpha$ as shape and $\beta$ as scale:

\begin{align}
    f(x;\alpha,\beta) = \frac{\beta^{\alpha}}{\Gamma(\alpha)} x^{\alpha-1} e^{\beta x}
\end{align}

Step 2. Set the proposal distribution, $g(x)$, as an Exponential dist with scale parameter of one:
\begin{align}
    g(x) = e^{-x}
\end{align}
\textcolor{blue}{More generally, we can use any scale parameter for the exponential. For the purposes of this discussion, we just need the scale parameter to be fixed. I think it's pretty reasonable to keep $\lambda=1$ for now to avoid cluttering our formulas, although eventually we'll need to do the general case.}\\

Step 3. The pdf of weights is $w(x;\alpha,\beta) = \frac{f(x;\alpha,\beta)}{g(x)}$. \textcolor{blue}{This actually isn't quite the pdf of the weights. Instead, the $X$s are iid from $g$, and the weights are obtained by evaluating $w$ at the simulated $X$s. The distribution on the weights is then induced by the distribution on $X$ and the functional relationship between $X$ and $W$. If the words ``pushforward measure'' help clarify things, that's exactly what's happening here. If not, $W$ is a transformation of $X$. In principle, we can get the pdf of $W$ by computing the Jacobian of the (inverse) transformation (i.e. the derivative of the inverse of the likelihood ratio function). Personally, I prefer to work directly with the CDF or survival function; for one, I think it's easier, and for two, we need the survival function for step 4 anyway.}\\

Step 4. Use the pdf in step 3 and compute its tail function as described in Pickands paper:

\begin{align}
    P(x) = \frac{F(X \geq u+x)}{F(X \geq u)}
\end{align}

where $F(.)$ is the CDF of weights as defined in step 3.

Step 5. Find $Q_3$, and median as described in the paper. Compute the $c$ and $a$. 


\section{William's Derivation}

\textcolor{red}{I found a few mistakes. See the git log for changes. I still think my new answer is wrong, but at least it's a bit more reasonable. I'll make another pass at some point and see if I notice more mistakes.}

I'm going to mostly stick to the above notation, but I would like to use the general exponential distribution until I find myself needing to set $\lambda=1$. I will also suppress dependence on parameters in the various densities to avoid extra typing. Thus, $g(x) = \exp(-x/\lambda)/\lambda$.

At a high-level, my plan is to compute the survival function of the weights, as well as their density and the derivative of their density. I can then use Equation (1.1.30) on page 15 of \citet{deH06} to (hopefully) compute the tail index. There are enough steps here that it's going to take a few days' work. One step at a time.

To start, we note that the weight, $W$, can be written as a random variable in the following way.
%
\begin{align}
    W(X) &= \frac{f(X)}{g(X)}\\
    &= \frac{\lambda}{\beta^\alpha \Gamma(\alpha)} X^{\alpha - 1} \exp\left[ -X \left( \frac{1}{\beta} + \frac{1}{\lambda} \right) \right]\\
    &=: c X^{\alpha - 1} \exp(-X / \gamma)
\end{align}
%
where $c = \lambda / \beta^\alpha \Gamma(\alpha)$, and $\gamma = (1/\beta + 1/\lambda)^{-1}$. I doubt that it will every be relevant, but I think it's cute that $\gamma$ is a harmonic mean. 

We can now work out the survival function of $W$. We write $\sW$ for the inconveniently named Lambert-W function, which is the inverse function of $x \mapsto x e^x$. I.e. $\sW$ satisfies $\sW(x) \exp[\sW(x)] = x$.
%
\begin{align}
    \bP (W > w) &= \bP \left( X^{\alpha - 1} e^{-X/\gamma} > \frac{w}{c} \right) \label{eq:W_surv1}\\
    &= \bP \left( X > - (\alpha - 1) \gamma \cdot \sW \left[ - \frac{(w/c)^{1/(\alpha-1)}}{(\alpha - 1) \gamma} \right] \right) \label{eq:W_surv2}\\
    &= \exp \left( \frac{(\alpha - 1) \gamma}{\lambda} \cdot \sW \left[ - \frac{(w/c)^{1/(\alpha-1)}}{(\alpha - 1) \gamma} \right] \right) \label{eq:W_surv3}
\end{align}
%
where we pass from (\ref{eq:W_surv1}) to (\ref{eq:W_surv2}) with the help of Wolfram Alpha.

\subsection{PDF}
\label{sec:pdf}

Next, we need the PDF of $W$, and later its derivative. I'm going to find it easier to do this in stages. Let $\bar{\varphi}(w) = \bP(W > w)$ and $\eta$ be the argument to $\sW$ in (\ref{eq:W_surv3}). The (negative) PDF of $w$ is obtained by differentiating $\bar{\varphi}$. Note that the derivative of $\sW$ can be obtained implicitly from its\footnote{Usually, I try not to use ``it'' to refer to anything in academic writing (Tom drilled this into me during my master's thesis revisions). Here however, I think it's a pretty good fit and doing anything else would be very wordy.} defining equation
%
\begin{align}
    \nabla_w \bar{\varphi}(w) &=  \frac{(\alpha - 1) \gamma}{\lambda} \bar{\varphi}(w) \nabla_w \sW (\eta)\\
    \nabla_w \sW(\eta) &= \frac{\sW(\eta)}{\eta [ 1 + \sW(\eta)]} \nabla_w \eta\\
    \nabla_w \eta &= - \frac{1}{c \gamma (\alpha - 1)^2} \left( \frac{w}{c} \right)^{\frac{1}{\alpha - 1} - 1} = \frac{\eta}{w(\alpha - 1)} \label{eq:nabla_eta}
\end{align}
%
Putting this all together, and after a surprising amount of cancellation, I get
%
\begin{align}
    f_W(w) &:= -\nabla_w \bar{\varphi}(w)\\
    &= - \bar{\varphi}(w) \frac{\gamma}{\lambda w} \cdot \frac{\sW(\eta)}{1 + \sW(\eta)}
\end{align}

\subsection{Derivative of 1 over Hazard Rate}

We return now to Theorem 1.1.8 of \citet{deH06}, specifically expression (1.1.29)\footnote{Note that, in survival analysis, the hazard rate of a distribution is defined as the density over the survival function. The quantity being differentiated in (1.1.29) before taking the limit is thus the reciprocal of the hazard rate of $W$}. We first compute the survival function of $W$ over its density, wherein we get some nice cancellation.
%
\begin{align}
    \frac{\bar{\varphi}(w)}{f_W(w)} &= - \frac{\lambda w}{\gamma} \cdot \frac{1 + \sW(\eta)}{\sW(\eta)} \label{eq:recip_hazard}
\end{align}
%
where $\sW$ and $\eta$ are defined in Section \ref{sec:pdf}. We now need to differentiate the expression in \ref{eq:recip_hazard}. Fortunately, we can recycle identities (\ref{eq:W_surv2}) and (\ref{eq:W_surv3}). We first present some identities which help with simplification, then proceed with computing the derivative.
%
\begin{align}
    \nabla_w \sW(\eta) &= \partial \sW(\eta) \cdot \partial \eta\\
    &= \frac{1}{w(\alpha - 1)} \cdot \frac{\sW(\eta)}{ 1 + \sW(\eta)}\\
    \nabla_w \frac{1 + \sW(\eta)}{\sW(\eta)} &= \nabla_w \frac{1}{\swe}\\
    &= \frac{-\nabla_w \swe}{\swe^2}\\
    &= - \frac{1}{w (\alpha - 1) \swe (1 + \swe)}\\
    \nabla_w \frac{\bar{\varphi}(w)}{f_W(w)} &= - \frac{\lambda}{\gamma} \left[ \frac{1 + \swe}{\swe} + w \nabla_w \frac{1 + \sW(\eta)}{\sW(\eta)} \right]\\
    &= \frac{\lambda}{\gamma} \left[ \frac{1}{(\alpha - 1) \swe (1 + \swe)} - \frac{1 + \swe}{\swe} \right] \label{eq:grad_recip_hazard}
\end{align}
%
All that remains is to compute the limit of (\ref{eq:grad_recip_hazard}) as $w \uparrow \infty$. Note that $\eta \rightarrow - \infty$ as $w \rightarrow \infty$, so $\sW(\eta) \rightarrow - \infty$ as well. Re-write (\ref{eq:grad_recip_hazard}) as $(\lambda / \gamma) [ A - B]$. We now explore the asymptotic behaviour of $A$ and $B$. This is actually pretty straightforward: $A \rightarrow 0$ and $B \rightarrow 1$. Thus, the tail index, $\nabla_w [\bar{\varphi}(w) / f_W(w)]$, goes to $- \lambda / \gamma$ as $w \uparrow \infty$. Expanding this ratio, we get
%
\begin{align}
    - \frac{\lambda}{\gamma} &= - \frac{\lambda}{(1/\beta + 1/\lambda)^{-1}}\\
    &= - \left( 1 + \frac{\lambda}{\beta} \right)
\end{align}

\subsection{Discussion}

This final conclusion, while pleasantly simple, cannot possibly be correct. Surely, the tail index must depend on both parameters of the target distribution. Frankly, an incorrect answer isn't terribly surprising here. It's a long derivation with lots of room for mistakes. If I have time between now and our next meeting, I'll spend some time reviewing my work. If not, I would like to go over it again with you Payman, both to explain my reasoning and to double-check my work.

\bibliographystyle{apalike}
\bibliography{MyBib}

\end{document}